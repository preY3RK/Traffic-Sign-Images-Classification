{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bg9FInuuBps",
        "outputId": "9154217e-b061-4df3-8a05-7ccd34264481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import h5py\n",
        "drive.mount('/content/drive')\n",
        "file_path=\"/content/drive/MyDrive/dataset_ts_light_version.hdf5\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "TeX54cgm3Lc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(file_path, 'r') as f:\n",
        "  for key in f.keys():\n",
        "    print(f\"{key}: shape={f[key].shape}\")\n",
        "\n",
        "  X_train= f['x_train'][:]\n",
        "  y_train= f['y_train'][:]\n",
        "\n",
        "  X_val= f['x_validation'][:]\n",
        "  y_val= f['y_validation'][:]\n",
        "\n",
        "  X_test= f['x_test'][:]\n",
        "  y_test= f['y_test'][:]"
      ],
      "metadata": {
        "id": "8_nU3lKvuh2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eaf3bfa-c508-407e-ee33-64f0c35ce16d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test: shape=(7766, 48, 48, 3)\n",
            "x_train: shape=(90601, 48, 48, 3)\n",
            "x_validation: shape=(31063, 48, 48, 3)\n",
            "y_test: shape=(7766,)\n",
            "y_train: shape=(90601,)\n",
            "y_validation: shape=(31063,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train.reshape(X_train.shape[0], -1)\n",
        "del X_train\n",
        "means = X.mean(axis=1, keepdims=True)\n",
        "stds = X.std(axis=1, keepdims=True) + 1e-8\n",
        "X_standardized = (X-means)/stds\n",
        "X_standardized[:5]\n",
        "del X\n",
        "del means\n",
        "del stds\n",
        "# deleting numpy arrays to save RAM"
      ],
      "metadata": {
        "id": "c7U8U7JcwcEj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_standardized.shape"
      ],
      "metadata": {
        "id": "R4dkeT8RsNpZ",
        "outputId": "4b49d7f9-bd3c-43f0-e432-d8d1accb295e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90601, 6912)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "model_new = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=100)\n",
        "#10 iter - 0.7841874839041978 accuracy\n",
        "#20 iter - 0.912052536698429 accuracy\n",
        "#30 iter - 0.93638938964718 accuracy\n",
        "#40 iter - 0.9500386299253155 accuracy\n",
        "#100 iter - 0.9658768993046614 accuracy"
      ],
      "metadata": {
        "id": "St_wVwJ0lavL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_new.fit(X_standardized, y_train)\n",
        "# be careful, this reaches 9.5 GB ram used\n",
        "del X_standardized"
      ],
      "metadata": {
        "id": "IIkQeBG-o2Z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94351587-330f-4ad2-e6e6-f2733b96a6b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_test.reshape(X_test.shape[0], -1)\n",
        "del X_test\n",
        "means = X.mean(axis=1, keepdims=True)\n",
        "stds = X.std(axis=1, keepdims=True) + 1e-8\n",
        "X_test_standardized = (X-means)/stds\n",
        "X_test_standardized[:5]\n",
        "del X\n",
        "del means\n",
        "del stds\n",
        "# deleting numpy arrays to save RAM"
      ],
      "metadata": {
        "id": "6wK4HqwpwoZ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "07c27388-4dc7-4158-964d-0efe4b4b611c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-40395464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test_standardized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predict = model_new.predict(X_test_standardized)\n",
        "accuracy = accuracy_score(y_test, y_test_predict)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AljcTgFjwWlZ",
        "outputId": "c56127d6-f59f-4ed3-f930-240fc42a9cee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9658768993046614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report with Additional Features:\")\n",
        "print(classification_report(y_test, y_test_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNhKEGfrxfAL",
        "outputId": "2b0420b9-60d0-4602-bed5-1e288cbb83ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report with Additional Features:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       177\n",
            "           1       0.98      0.94      0.96       193\n",
            "           2       0.97      0.93      0.95       195\n",
            "           3       0.96      0.94      0.95       159\n",
            "           4       0.97      0.96      0.97       180\n",
            "           5       0.92      0.91      0.91       170\n",
            "           6       0.98      0.98      0.98       189\n",
            "           7       0.96      0.94      0.95       189\n",
            "           8       0.92      0.95      0.94       213\n",
            "           9       0.97      0.96      0.97       168\n",
            "          10       0.96      0.98      0.97       177\n",
            "          11       0.96      0.93      0.95       184\n",
            "          12       0.98      0.98      0.98       193\n",
            "          13       0.99      0.99      0.99       174\n",
            "          14       0.98      0.98      0.98       185\n",
            "          15       0.97      0.99      0.98       194\n",
            "          16       0.98      0.99      0.99       181\n",
            "          17       0.96      0.98      0.97       159\n",
            "          18       0.92      0.93      0.93       190\n",
            "          19       0.96      0.97      0.96       180\n",
            "          20       0.92      0.91      0.92       174\n",
            "          21       0.97      0.97      0.97       191\n",
            "          22       0.97      0.99      0.98       178\n",
            "          23       0.96      0.94      0.95       177\n",
            "          24       0.96      0.95      0.96       217\n",
            "          25       0.93      0.93      0.93       190\n",
            "          26       0.96      0.95      0.96       184\n",
            "          27       0.97      0.97      0.97       179\n",
            "          28       0.99      0.97      0.98       143\n",
            "          29       0.95      0.97      0.96       173\n",
            "          30       0.92      0.94      0.93       176\n",
            "          31       0.92      0.90      0.91       177\n",
            "          32       0.96      0.99      0.98       186\n",
            "          33       0.99      0.99      0.99       197\n",
            "          34       0.98      0.99      0.98       164\n",
            "          35       0.99      0.97      0.98       184\n",
            "          36       0.99      0.99      0.99       182\n",
            "          37       1.00      1.00      1.00       187\n",
            "          38       0.98      0.99      0.99       174\n",
            "          39       1.00      1.00      1.00       169\n",
            "          40       0.99      0.98      0.99       173\n",
            "          41       0.96      0.98      0.97       166\n",
            "          42       0.99      0.99      0.99       175\n",
            "\n",
            "    accuracy                           0.97      7766\n",
            "   macro avg       0.97      0.97      0.97      7766\n",
            "weighted avg       0.97      0.97      0.97      7766\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
