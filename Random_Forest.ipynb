{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext cuml.accel\n",
        "\n",
        "from cuml.common import logger;\n",
        "logger.set_level(logger.level_enum.debug)"
      ],
      "metadata": {
        "id": "pE5VZVGIHybb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import h5py\n",
        "from scipy.stats import randint, uniform\n",
        "drive.mount(\"/content/drive\")\n",
        "file_path=\"/content/drive/MyDrive/dataset_ts_light_version.hdf5\""
      ],
      "metadata": {
        "id": "wrhbCuYKTBoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(file_path, \"r\") as f:\n",
        "\n",
        "  X_train= f[\"x_train\"][:]\n",
        "  y_train= f[\"y_train\"][:]\n",
        "\n",
        "  X_val= f[\"x_validation\"][:]\n",
        "  y_val= f[\"y_validation\"][:]\n",
        "\n",
        "  X_test= f[\"x_test\"][:]\n",
        "  y_test= f[\"y_test\"][:]\n",
        "\n",
        "  X_train = np.concatenate((X_train, X_val), axis=0)\n",
        "  y_train = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "del X_val, y_val"
      ],
      "metadata": {
        "id": "1tuJAt5aOn92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "  reshaped_data = data.reshape(data.shape[0], -1)\n",
        "  means = reshaped_data.mean(axis=1, keepdims=True)\n",
        "  stds = reshaped_data.std(axis=1, keepdims=True) + 1e-8\n",
        "  preprocessed_data = (reshaped_data-means)/stds\n",
        "  return preprocessed_data\n",
        "\n",
        "X_train = preprocess(X_train)\n",
        "X_test = preprocess(X_test)\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=42)"
      ],
      "metadata": {
        "id": "LMkTjN-FoVI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators_range = (100, 180)\n",
        "max_depth_range = (10, 18)\n",
        "min_samples_leaf_range = (1, 8)\n",
        "percent_of_data = 0.01\n",
        "\n",
        "param_dist = {\"n_estimators\": randint(n_estimators_range[0], n_estimators_range[1]),\n",
        "              \"max_depth\": randint(max_depth_range[0], max_depth_range[1]),\n",
        "              \"min_samples_leaf\": randint(min_samples_leaf_range[0], min_samples_leaf_range[1]),\n",
        "              }\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rand_search = HalvingRandomSearchCV(rf, param_distributions=param_dist, max_resources=round(X_train.shape[0]*percent_of_data), verbose=10, random_state=42)\n",
        "\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "del rf, X_train, y_train\n",
        "\n",
        "y_pred = rand_search.best_estimator_.predict(X_test)\n",
        "\n",
        "del X_test\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "wrong_images_index = []\n",
        "\n",
        "for i in range(0, y_test.shape[0]):\n",
        "  if y_pred[i] != y_test[i]:\n",
        "    wrong_images_index.append(i)\n",
        "\n",
        "del y_test, y_pred\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/run_info.txt\"\n",
        "with open(file_path, \"a\") as f:\n",
        "  f.write(f\"\\nNew run:\\nParameter distribution:\\nn_estimators_range: {n_estimators_range}, max_depth_range: {max_depth_range}, min_samples_leaf_range: {min_samples_leaf_range}, percent_of_data: {percent_of_data}\\nAccuracy: {accuracy}\\nBest hyperparameters: {rand_search.best_params_}\\nIncorrectly classified images: {wrong_images_index}\\nNumber of incorrectly classified images: {len(wrong_images_index)}\")"
      ],
      "metadata": {
        "id": "OLNOJ_MaGxvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}